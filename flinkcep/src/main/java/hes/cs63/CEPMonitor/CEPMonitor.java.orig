package hes.cs63.CEPMonitor;


import hes.cs63.CEPMonitor.Fishing.IllegalFishing;
import hes.cs63.CEPMonitor.Fishing.SuspiciousFishing;
import hes.cs63.CEPMonitor.Gaps.Gap;
import hes.cs63.CEPMonitor.Gaps.GapMessageSerializer;
import hes.cs63.CEPMonitor.Gaps.SuspiciousGap;
import hes.cs63.CEPMonitor.VesselsCoTravel.coTravelInfo;
import hes.cs63.CEPMonitor.VesselsCoTravel.coTravel;
import hes.cs63.CEPMonitor.VesselsCoTravel.coTravelSerializer;
<<<<<<< HEAD
=======
import org.apache.flink.api.common.ExecutionConfig;
>>>>>>> 6e3cb0cf7a370bd8dd2a80b8e163cc613c2d3378
import org.apache.flink.api.java.functions.KeySelector;
import org.apache.flink.api.java.utils.ParameterTool;
import org.apache.flink.cep.CEP;
import org.apache.flink.cep.PatternStream;
import org.apache.flink.cep.pattern.Pattern;
import org.apache.flink.core.fs.FileSystem;
import org.apache.flink.core.fs.FileSystem.WriteMode;
import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode;
import org.apache.flink.streaming.api.TimeCharacteristic;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.IngestionTimeExtractor;
import org.apache.flink.streaming.api.functions.timestamps.AscendingTimestampExtractor;
import org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer09;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer09;

import hes.cs63.CEPMonitor.Acceleration.Acceleration;
import hes.cs63.CEPMonitor.Acceleration.SuspiciousAcceleration;

import java.util.Properties;
import hes.cs63.CEPMonitor.SpeedVesselType.*;
import hes.cs63.CEPMonitor.CoGHeading.*;

public class CEPMonitor {

    public static void main(String[] args) throws Exception {
    	
    	String sql = "SELECT * FROM `stackoverflow`";
        //Acceleration.readcsv();
        System.getenv("APP_HOME");
        StreamExecutionEnvironment env =
                StreamExecutionEnvironment.getExecutionEnvironment();

        ParameterTool parameterTool = ParameterTool.fromArgs(args);
        Properties props=parameterTool.getProperties();
        env.enableCheckpointing(1000).
                setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

        // Input stream of monitoring events
        DataStream<AisMessage> messageStream = env
                .addSource(new FlinkKafkaConsumer09<>(
                                    parameterTool.getRequired("topic"),
                                    new AisMessageDeserializer(),
                                   props))
                .assignTimestampsAndWatermarks(new Watermarks());

        DataStream<AisMessage> partitionedInput = messageStream.keyBy(
                new KeySelector<AisMessage, Integer>() {
                    @Override
                    public Integer getKey(AisMessage value) throws Exception {
                        return value.getMmsi();
                    }
        });

        DataStream<AisMessage> nonPartitionedInput = messageStream;
<<<<<<< HEAD

=======
     
       
>>>>>>> 6e3cb0cf7a370bd8dd2a80b8e163cc613c2d3378
        ///////////////////////////////////Gaps in the messages of a single vessell////////////////////////////////////////////
        Pattern<AisMessage, ?> gapPattern = Gap.patternGap();
        PatternStream<AisMessage> patternGapStream = CEP.pattern(partitionedInput,gapPattern);
        DataStream<SuspiciousGap> gaps = Gap.suspiciousGapsStream(patternGapStream);
<<<<<<< HEAD
        final SingleOutputStreamOperator<SuspiciousGap> topic_2_gap = gaps.map(v -> v.getGapObj());
=======

        final SingleOutputStreamOperator<SuspiciousGap> topic_2_gap = gaps.map(v -> v.getGapObj());

>>>>>>> 6e3cb0cf7a370bd8dd2a80b8e163cc613c2d3378
        FlinkKafkaProducer09<SuspiciousGap> gapProducer = new FlinkKafkaProducer09<SuspiciousGap>(

                parameterTool.getRequired("topic_output_gap"),    // target topic
                new GapMessageSerializer(),
                parameterTool.getProperties());   // serialization schema

        topic_2_gap.addSink(gapProducer);
<<<<<<< HEAD
=======
        
        
>>>>>>> 6e3cb0cf7a370bd8dd2a80b8e163cc613c2d3378
        ///////////////////////////////////Gaps in the messages of a single vessell////////////////////////////////////////////

        ///////////////////////////////////Pairs of Vessels moving closely////////////////////////////////////////////
        Pattern<AisMessage, ?> coTravelPattern = coTravel.patternCoTravel();
        PatternStream<AisMessage> patternCoTravelStream = CEP.pattern(nonPartitionedInput,coTravelPattern);
        DataStream<coTravelInfo> coTravel = hes.cs63.CEPMonitor.VesselsCoTravel.coTravel.suspiciousCoTravelStream(patternCoTravelStream);

<<<<<<< HEAD


        ///////////////////////////////////Pairs of Vessels moving closely////////////////////////////////////////////
        Pattern<AisMessage, ?> coTravelPattern = coTravel.patternCoTravel();
        PatternStream<AisMessage> patternCoTravelStream = CEP.pattern(nonPartitionedInput,coTravelPattern);
        DataStream<coTravelInfo> coTravel = hes.cs63.CEPMonitor.VesselsCoTravel.coTravel.suspiciousCoTravelStream(patternCoTravelStream);
        //coTravel.map(v ->v.getSuspiciousCoTravelInfo()).writeAsText("/home/cer/Desktop/suspicious.txt", FileSystem.WriteMode.OVERWRITE);
        final SingleOutputStreamOperator<coTravelInfo> topic_2_co = coTravel.map(v -> v.getSuspiciousCoTravelInfo());
        FlinkKafkaProducer09<coTravelInfo> coProducer = new FlinkKafkaProducer09<coTravelInfo>(
                parameterTool.getRequired("topic_output_co"),    // target topic
                new coTravelSerializer(),
                parameterTool.getProperties());   // serialization schema

        topic_2_gap.addSink(gapProducer);
        topic_2_co.addSink(coProducer);
        ///////////////////////////////////Pairs of Vessels moving closely////////////////////////////////////////////


=======
        final SingleOutputStreamOperator<coTravelInfo> topic_2_co = coTravel.map(v -> v.getSuspiciousCoTravelInfo());
>>>>>>> 6e3cb0cf7a370bd8dd2a80b8e163cc613c2d3378

        FlinkKafkaProducer09<coTravelInfo> coProducer = new FlinkKafkaProducer09<coTravelInfo>(
                parameterTool.getRequired("topic_output_co"),    // target topic
                new coTravelSerializer(),
                parameterTool.getProperties());
        topic_2_co.addSink(coProducer);

        ///////////////////////////////////Pairs of Vessels moving closely////////////////////////////////////////////
        
        

        //////////////////////////////////Fast Approach//////////////////////////////////////////////////////////////

        /*Pattern<AisMessage, ?> Accelarationattern= Acceleration.patternAcceleration();
		PatternStream<AisMessage> patternSAccelarationStream = CEP.pattern(nonPartitionedInput,Accelarationattern);
		DataStream<SuspiciousAcceleration> accelerations = Acceleration.suspiciousAccelerationsStream(patternSAccelarationStream);

		accelerations.map(v -> v.findAccelerationObjToString()).writeAsText("/home/cer/Desktop/temp/fast_approach.txt", WriteMode.OVERWRITE);
     	accelerations.map(v -> v.findAccelerationObjQGIS()).writeAsText("/home/cer/Desktop/temp/fast_approachQGIS.csv", WriteMode.OVERWRITE);*/
		
        //////////////////////////////////Fast Approach//////////////////////////////////////////////////////////////



        //////////////////////////////////Fishing//////////////////////////////////////////////////////////////

        Pattern<AisMessage, ?> fishingPattern= IllegalFishing.patternFishing();
        PatternStream<AisMessage> patternFishingStream = CEP.pattern(partitionedInput,fishingPattern);
        DataStream<SuspiciousFishing> fishing = IllegalFishing.suspiciousFishingStream(patternFishingStream);
        fishing.map(v -> v.findFishing()).writeAsText("/home/cer/Desktop/temp/fishing.txt", FileSystem.WriteMode.OVERWRITE);
        fishing.map(v -> v.findFishingQGIS()).writeAsText("/home/cer/Desktop/temp/fishingQGIS.csv", FileSystem.WriteMode.OVERWRITE);


        //////////////////////////////////Fishing//////////////////////////////////////////////////////////////
        
      
        
        ///////////////////////////////////Suspicious speed in the messages of a single vessell////////////////////////////////////////////
        Pattern<AisMessage, ?> suspiciousSpeedPattern = SpeedVesselType.patternSpeedVesselType();
        PatternStream<AisMessage> patternsuspiciousSpeedStream= CEP.pattern(partitionedInput,suspiciousSpeedPattern);
        DataStream<SuspiciousSpeedVesselType> suspiciousspeed = SpeedVesselType.suspiciousSpeedVesselTypeStream(patternsuspiciousSpeedStream);

        suspiciousspeed.map(v -> v.findSpeed()).writeAsText("/home/cer/Desktop/spacious_speed.csv", WriteMode.OVERWRITE);
		System.out.print("edwwwww");
    	
        
        ///////////////////////////////////Suspicious heading in the messages of a single vessell////////////////////////////////////////////
        Pattern<AisMessage, ?> suspiciousHeadingPattern = CourseHeading.patternSpaciousHeading();
        PatternStream<AisMessage> patternsuspiciouHeadingStream= CEP.pattern(partitionedInput,suspiciousHeadingPattern);
        DataStream<SuspiciousCourseHeading> suspiciousHeading = CourseHeading.suspiciousSpeedVesselTypeStream(patternsuspiciouHeadingStream);
        
        suspiciousHeading.map(v -> v.findHeading()).writeAsText("/home/cer/Desktop/spacious_heading.csv", WriteMode.OVERWRITE);
		

        
        
        
        
        env.execute("Trajentory evens");

    }
}
